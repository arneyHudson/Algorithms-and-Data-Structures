{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35382adb-0c08-4af6-93e3-3af460ce4e65",
   "metadata": {},
   "source": [
    "# Hudson Arney\n",
    "# Lab 1 - Insertion and Selected Sort Benchmarking\n",
    "## Algorithms and Advanced Data Structures - CSC 3310 001\n",
    "\n",
    "## Introduction:\n",
    "In this lab I will attempt to ipmlement and benchmark the insertion sort and selected sort algorithms to gain a better understanding of how they work, and what situations they will be best for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6546877-afad-4e2f-9a1b-b53431f85da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ea3d7",
   "metadata": {},
   "source": [
    "## 1. Implement Insertion and Selection Sort\n",
    "###         2. Implement the following functions in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15529400-e507-4651-80b4-29e1cc812dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Insertion Sort\n",
    "def insertion_sort(lst):\n",
    "    for i in range(1, len(lst)):\n",
    "        key = lst[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and key < lst[j]:\n",
    "            lst[j + 1] = lst[j]\n",
    "            j -= 1\n",
    "        lst[j + 1] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce02d39-d11e-4044-b069-c2ad8c9be5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Selection Sort\n",
    "def selection_sort(lst):\n",
    "    for i in range(len(lst)):\n",
    "        min_index = i\n",
    "        for j in range(i + 1, len(lst)):\n",
    "            if lst[j] < lst[min_index]:\n",
    "                min_index = j\n",
    "        lst[i], lst[min_index] = lst[min_index], lst[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc0786",
   "metadata": {},
   "source": [
    "### 3. Write tests to ensure that the two algorithms are implemented correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4848f1c-95ec-478a-9c58-94c2c76c9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run tests on sorting algorithms\n",
    "def test_sorting_algorithms():\n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        [5, 2, 9, 1, 5, 6],\n",
    "        [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "        [],\n",
    "        [1],\n",
    "        [3, 3, 3, 3],\n",
    "    ]\n",
    "\n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        sorted_copy = sorted(test_case)\n",
    "        insertion_sort(test_case)\n",
    "        assert test_case == sorted_copy, f\"Insertion Sort Test {i + 1} failed\"\n",
    "\n",
    "        selection_sort(test_case)\n",
    "        assert test_case == sorted_copy, f\"Selection Sort Test {i + 1} failed\"\n",
    "\n",
    "    print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d994ee51-4ccf-4213-84b9-a881e5d3032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Run tests\n",
    "test_sorting_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a496d",
   "metadata": {},
   "source": [
    "## 2. Write a Benchmark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca8d149-d358-4a17-bb47-8463d612a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_sorting_algorithms():\n",
    "    sizes = [10, 100, 1000, 10000, 100000]\n",
    "    algorithms = [insertion_sort, selection_sort]\n",
    "    cases = ['Best', 'Average', 'Worst']\n",
    "    results = []\n",
    "\n",
    "    for size in sizes:\n",
    "        for algorithm in algorithms:\n",
    "            for case in cases:\n",
    "                if case == 'Best':\n",
    "                    # Create a sorted list\n",
    "                    lst = list(range(1, size + 1))\n",
    "                elif case == 'Average':\n",
    "                    # Create a randomly shuffled list\n",
    "                    lst = [random.randint(1, 1000) for _ in range(size)]\n",
    "                elif case == 'Worst':\n",
    "                    # Create a reverse sorted list\n",
    "                    lst = list(range(size, 0, -1))\n",
    "                \n",
    "                start_time = time.perf_counter() # Make sure the time is only counted when sorting the algorithm\n",
    "                algorithm(lst)\n",
    "                end_time = time.perf_counter()\n",
    "                execution_time = end_time - start_time\n",
    "                \n",
    "                results.append((algorithm.__name__, size, case, execution_time))\n",
    "    \n",
    "    data = pd.DataFrame(results, columns=['algorithm', 'size', 'case', 'time'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a491c7",
   "metadata": {},
   "source": [
    "### 3. Design and Execute the Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caa55c-bed6-4d92-9620-08e157ddb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmark\n",
    "data = benchmark_sorting_algorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923d714",
   "metadata": {},
   "source": [
    "## 4. Validating Formal Run Times\n",
    "### 1. Fit a linear regression model to the logarithms (base doesn't matter) of the list sizes (s) and run times (r) to estimate the slope (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9993fd-bbdc-4747-af31-246829737587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate the slope (m) using linear regression\n",
    "def estimate_slope(list_sizes, run_times):\n",
    "    m, b, _, _, _ = linregress(np.log(list_sizes), np.log(run_times))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dc437",
   "metadata": {},
   "source": [
    " In the graphs below we can see all cases for selected sort the slope is around 1.9, which is nearly a quadratic function, showing that selection sort regardless of case, is O(n^2)\n",
    " Insertion sort is a little different where if given the best case, the slope is around __ which is nearly constant time, If given the average case and worst case however, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe685eb",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis of Algorithm Run Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparative_analysis(data):\n",
    "    algorithms = set(data['algorithm'])\n",
    "    cases = set(data['case'])\n",
    "\n",
    "    colors = ['g', 'r', 'b']\n",
    "    list_sizes = np.log(sorted(set(data['size'])))\n",
    "\n",
    "    # Two plots that show all cases for each algorithm\n",
    "    for algorithm in algorithms:\n",
    "        for case, color in zip(cases, colors):\n",
    "            algorithm_data = data[(data['algorithm'] == algorithm) & (data['case'] == case)]\n",
    "            list_sizes = algorithm_data['size']\n",
    "            run_times = algorithm_data['time']\n",
    "            list_sizes_log = np.log(list_sizes)\n",
    "\n",
    "            m = estimate_slope(list_sizes, run_times)\n",
    "\n",
    "            plt.plot(list_sizes_log, run_times, label=f'{case} case (m={m:.3f})', color=color)\n",
    "\n",
    "        plt.xlabel('List Size', fontsize=18)\n",
    "        plt.ylabel('Run Time (seconds)', fontsize=18)\n",
    "        plt.title(f'{algorithm} Algorithm', fontsize=20)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "    # Separate plot for each case with the two algorithms\n",
    "    for case in cases:\n",
    "        for algorithm, color in zip(algorithms, colors):\n",
    "            algorithm_data = data[(data['algorithm'] == algorithm) & (data['case'] == case)]\n",
    "            list_sizes_log = np.log(algorithm_data['size'])\n",
    "            list_sizes_log = algorithm_data['size']\n",
    "            run_times = algorithm_data['time']\n",
    "\n",
    "            m = estimate_slope(list_sizes, run_times)\n",
    "\n",
    "            plt.plot(list_sizes_log, run_times, label=f'{algorithm} (m={m:.3f})', color=color)\n",
    "\n",
    "        plt.xlabel('List Size', fontsize=18)\n",
    "        plt.ylabel('Run Time (seconds)', fontsize=18)\n",
    "        plt.title(f'{case} Case', fontsize=20)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_analysis(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c89bb5",
   "metadata": {},
   "source": [
    "## 6. Reflection Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb475b",
   "metadata": {},
   "source": [
    "### 1. Create a table of the theoretical and estimated run time functions for the 6 combinations (2algorithms, 3 cases). Do your estimates match the theory? (If not, you may have made a mistake somewhere.)\n",
    "\n",
    "| Algorithm      | Size       | Case       | Theoretical Time Complexity | Estimated Run Time (seconds) |\n",
    "|----------------|------------|------------|-----------------------------|------------------------------|\n",
    "| Insertion Sort | Size 10    | Best       | O(n)                        | 0.000006                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.000013                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.000011                     |\n",
    "|                | Size 100   | Best       | O(n)                        | 0.000096                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.000322                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.000599                     |\n",
    "|                | Size 1000  | Best       | O(n)                        | 0.000158                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.038245                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.058509                     |\n",
    "|                | Size 10000 | Best       | O(n)                        | 0.001601                     |\n",
    "|                |            | Average    | O(n^2)                      | 3.442951                     |\n",
    "|                |            | Worst      | O(n^2)                      | 5.524937                     |\n",
    "|                | Size 100000| Best       | O(n)                        | 0.015993                     |\n",
    "|                |            | Average    | O(n^2)                      | 280.447600                   |\n",
    "|                |            | Worst      | O(n^2)                      | 490.922795                   |\n",
    "| Selection Sort | Size 10    | Best       | O(n^2)                      | 0.000014                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.000019                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.000033                     |\n",
    "|                | Size 100   | Best       | O(n^2)                      | 0.000360                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.000423                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.000351                     |\n",
    "|                | Size 1000  | Best       | O(n^2)                      | 0.034365                     |\n",
    "|                |            | Average    | O(n^2)                      | 0.034946                     |\n",
    "|                |            | Worst      | O(n^2)                      | 0.035531                     |\n",
    "|                | Size 10000 | Best       | O(n^2)                      | 2.886178                     |\n",
    "|                |            | Average    | O(n^2)                      | 2.998222                     |\n",
    "|                |            | Worst      | O(n^2)                      | 3.623596                     |\n",
    "|                | Size 100000| Best       | O(n^2)                      | 288.508478                   |\n",
    "|                |            | Average    | O(n^2)                      | 303.247046                   |\n",
    "|                |            | Worst      | O(n^2)                      | 298.515603                   |\n",
    "\n",
    "<br>\n",
    "For Insertion Sort, the estimated run times align well with the theoretical complexities:<br>\n",
    "    Best case (O(n)): Estimated time matches closely.<br>\n",
    "    Average case (O(n^2)): Estimated time matches reasonably.<br>\n",
    "    Worst case (O(n^2)): Estimated time matches reasonably.<br>\n",
    "    \n",
    "For Selection Sort, the estimated run times also align well with the theoretical complexities:<br>\n",
    "    Best case (O(n^2)): Estimated time matches closely.<br>\n",
    "    Average case (O(n^2)): Estimated time matches closely.<br>\n",
    "    Worst case (O(n^2)): Estimated time matches closely.<br>\n",
    "Overall, the estimates appear to match the theoretical expectations. It is interesting to see that the cases didn't affect selection sort at all.<br>\n",
    "\n",
    "### 2. Which algorithm had a better run time than the other and for which case? Why do you think that one case was substantially faster for that algorithm? (Hint: focus on the inner loops.)<br>\n",
    "\n",
    "Insertion Sort for Best Case Scenarios:\n",
    "    Adaptive Efficiency: Insertion Sort excels when dealing with nearly sorted data.\n",
    "    Minimal Comparisons and Swaps: In best-case scenarios, where the list is already sorted, it requires very few comparisons and swaps.\n",
    "    Linear Time Complexity: Its time complexity in the best case is O(n), making it highly efficient for sorted lists.\n",
    "    Therefore, Insertion Sort is ideal for best-case scenarios where data is partially or fully sorted.<br>\n",
    "    \n",
    "Selection Sort for Average and Worst Cases, Amplified with List Size:\n",
    "    Fixed Behavior: Selection Sort always performs a fixed number of operations, regardless of initial order.\n",
    "    Quadratic Time Complexity: It has a quadratic time complexity (O(n^2)) in both average and worst cases.\n",
    "    Inefficiency with Larger Lists: As list size increases, its best case gets far outprefromed by the insertion sort best case.\n",
    "    The main downside to Selection Sort is it not adaptive and struggles with initial disorder.<br><br>\n",
    "    \n",
    "    \n",
    "### 3. Based on your results, which of the two sorting algorithms would you use in practice?<br>\n",
    "\n",
    "It greatly depends on the size of the dataset I am being given. In most cases you are going to have the average time complexity which for both happens to be O(n^2). I would assume that for the most part, the datasets I deal with in the future will be quite large, perhaps pushing the 10000 item range (again this is a rough assumption, maybe this isn't the case). If they are this large and seemed to be in a random order I would be inclined to used selection sort as it preformed similarly to insertion for average case, and much better for worst case. Although if I got a smaller dataset that already seemed to be somewhat sorted, insertion sort is a much better pick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58690203",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "I was able to create the two algorithms, insertion and selected sort correct and analyze the data it gave. I learned what cases work best for both algorithms and why that happens. I was albe to plot my findings with graphs that give a visualization to the data collected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
